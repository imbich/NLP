{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a0f58b",
   "metadata": {},
   "source": [
    "# Phân loại Văn bản với Mạng Nơ-ron Hồi quy (RNN/LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148e19f",
   "metadata": {},
   "source": [
    "# Phần 1: Nền tảng lý thuyết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5fdf8",
   "metadata": {},
   "source": [
    "- Mô hình Bag-of-Words: Biểu diễn mỗi văn bản bằng một vector tần suất từ (TF-IDF), sau đó dùng các thuật toán Machine Learning cổ điển như Logistic Regression, SVM\n",
    "\n",
    "- Mô hình Word2Vec + Dense Layer: Biểu diễn mỗi từ bằng 1 vector dày đặc, sau đó tính vector trung bình cho cả câu và đưa vào mạng nơ-ron đơn giản."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d1de1",
   "metadata": {},
   "source": [
    "## Phần 2: Lab thực hành"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3451b",
   "metadata": {},
   "source": [
    "### Bước 0: Thiết lập Môi trường và Tải dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116392c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x hwu/\n",
      "x hwu/categories.json\n",
      "x hwu/train_5.csv\n",
      "x hwu/train_10.csv\n",
      "x hwu/val.csv\n",
      "x hwu/test.csv\n",
      "x hwu/train.csv\n"
     ]
    }
   ],
   "source": [
    "# Lệnh shell để giải nén file\n",
    "!tar -xzvf ../Data/hwu.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df1e4945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8955, 2)\n",
      "Validation shape: (1077, 2)\n",
      "Test shape: (1077, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "intent",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ac6a854e-5b31-4f55-bd00-66b56c119554",
       "rows": [
        [
         "0",
         "text",
         "category"
        ],
        [
         "1",
         "what alarms do i have set right now",
         "alarm_query"
        ],
        [
         "2",
         "checkout today alarm of meeting",
         "alarm_query"
        ],
        [
         "3",
         "report alarm settings",
         "alarm_query"
        ],
        [
         "4",
         "see see for me the alarms that you have set tomorrow morning",
         "alarm_query"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what alarms do i have set right now</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>checkout today alarm of meeting</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report alarm settings</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>see see for me the alarms that you have set to...</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       intent\n",
       "0                                               text     category\n",
       "1                what alarms do i have set right now  alarm_query\n",
       "2                    checkout today alarm of meeting  alarm_query\n",
       "3                              report alarm settings  alarm_query\n",
       "4  see see for me the alarms that you have set to...  alarm_query"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dữ liệu có thể được phân tách bằng tab và không có header\n",
    "df_train = pd.read_csv('hwu/train.csv', header=None, names=['text', 'intent'])\n",
    "df_val = pd.read_csv('hwu/val.csv', header=None, names=['text', 'intent'])\n",
    "df_test = pd.read_csv('hwu/test.csv', header=None, names=['text', 'intent'])\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Validation shape:\", df_val.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "483ee570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# ... (Code để fit LabelEncoder trên toàn bộ tập intent và transform các tập train/val/test)\n",
    "intents = (\n",
    "    df_train['intent'].tolist() +\n",
    "    df_val['intent'].tolist() +\n",
    "    df_test['intent'].tolist()\n",
    ")\n",
    "classes = list(set(intents))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(intents)\n",
    "df_train[\"intent\"] = label_encoder.transform(df_train[\"intent\"])\n",
    "df_val[\"intent\"] = label_encoder.transform(df_val[\"intent\"])\n",
    "df_test[\"intent\"] = label_encoder.transform(df_test[\"intent\"])\n",
    "num_classes = len(set(intents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9a7df",
   "metadata": {},
   "source": [
    "### Nhiệm vụ: Pipeline TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ef4240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        19\n",
      "           1       1.00      0.73      0.84        11\n",
      "           2       0.81      0.89      0.85        19\n",
      "           3       1.00      0.75      0.86         8\n",
      "           4       0.92      0.80      0.86        15\n",
      "           5       0.93      1.00      0.96        13\n",
      "           6       0.48      0.53      0.50        19\n",
      "           7       0.89      0.89      0.89        19\n",
      "           8       0.82      0.74      0.78        19\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.59      0.68      0.63        19\n",
      "          11       0.67      0.75      0.71         8\n",
      "          12       0.74      0.89      0.81        19\n",
      "          13       0.78      0.88      0.82         8\n",
      "          14       0.83      0.79      0.81        19\n",
      "          15       0.92      0.63      0.75        19\n",
      "          16       0.77      0.89      0.83        19\n",
      "          17       1.00      1.00      1.00        19\n",
      "          18       1.00      1.00      1.00        19\n",
      "          19       1.00      1.00      1.00        19\n",
      "          20       0.90      1.00      0.95        19\n",
      "          21       1.00      0.95      0.97        19\n",
      "          22       1.00      1.00      1.00        12\n",
      "          23       0.95      1.00      0.97        19\n",
      "          24       0.95      1.00      0.97        19\n",
      "          25       0.36      0.26      0.30        19\n",
      "          26       0.90      1.00      0.95        19\n",
      "          27       1.00      1.00      1.00        16\n",
      "          28       1.00      0.95      0.97        19\n",
      "          29       0.75      0.79      0.77        19\n",
      "          30       0.91      0.83      0.87        12\n",
      "          31       0.89      0.89      0.89        19\n",
      "          32       0.67      0.67      0.67         3\n",
      "          33       0.92      0.86      0.89        14\n",
      "          34       0.80      0.89      0.84         9\n",
      "          35       0.78      1.00      0.88         7\n",
      "          36       0.68      0.79      0.73        19\n",
      "          37       0.75      0.79      0.77        19\n",
      "          38       0.85      0.89      0.87        19\n",
      "          39       0.65      0.61      0.63        18\n",
      "          40       0.71      0.53      0.61        19\n",
      "          41       1.00      0.57      0.73         7\n",
      "          42       0.75      0.63      0.69        19\n",
      "          43       0.95      0.95      0.95        19\n",
      "          44       0.81      0.68      0.74        19\n",
      "          45       0.58      0.74      0.65        19\n",
      "          46       1.00      0.84      0.91        19\n",
      "          47       0.89      0.84      0.86        19\n",
      "          48       0.94      0.89      0.92        19\n",
      "          49       0.82      0.95      0.88        19\n",
      "          50       0.48      0.58      0.52        19\n",
      "          51       0.92      0.86      0.89        14\n",
      "          52       1.00      0.95      0.97        19\n",
      "          53       0.83      0.79      0.81        19\n",
      "          54       0.81      0.89      0.85        19\n",
      "          55       1.00      1.00      1.00        10\n",
      "          56       0.95      1.00      0.97        19\n",
      "          57       0.80      0.89      0.84        18\n",
      "          58       0.83      0.79      0.81        19\n",
      "          59       0.89      0.89      0.89        19\n",
      "          60       0.68      0.79      0.73        19\n",
      "          61       1.00      1.00      1.00        18\n",
      "          62       0.94      0.79      0.86        19\n",
      "          63       1.00      0.95      0.97        19\n",
      "          64       0.65      0.68      0.67        19\n",
      "\n",
      "    accuracy                           0.84      1077\n",
      "   macro avg       0.83      0.82      0.82      1077\n",
      "weighted avg       0.84      0.84      0.83      1077\n",
      "\n",
      "Test loss 1.0528583042854829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, log_loss\n",
    "\n",
    "# 1. Tạo một pipeline với TfidfVectorizer và LogisticRegression\n",
    "tfidf_lr_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=5000),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "# 2. Huấn luyện pipeline trên tập train\n",
    "tfidf_lr_pipeline.fit(df_train[\"text\"], df_train[\"intent\"])\n",
    "\n",
    "# 3. Đánh giá trên tập test\n",
    "y_pred = tfidf_lr_pipeline.predict(df_test[\"text\"])\n",
    "loss_tfidf = log_loss(df_test[\"intent\"], tfidf_lr_pipeline.predict_proba(df_test[\"text\"]), labels=list(range(num_classes)))\n",
    "\n",
    "print(classification_report(y_true=df_test[\"intent\"], y_pred=y_pred))\n",
    "print(\"Test loss\", loss_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11ad42",
   "metadata": {},
   "source": [
    "### Nhiệm vụ 2: Pipeline Word2Vec (Trung bình) + Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7779732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc75ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0208 - loss: 4.1538 - val_accuracy: 0.0446 - val_loss: 4.1174\n",
      "Epoch 2/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0303 - loss: 4.1157 - val_accuracy: 0.0622 - val_loss: 4.0802\n",
      "Epoch 3/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0450 - loss: 4.0646 - val_accuracy: 0.0687 - val_loss: 4.0065\n",
      "Epoch 4/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0523 - loss: 3.9845 - val_accuracy: 0.0604 - val_loss: 3.9021\n",
      "Epoch 5/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0715 - loss: 3.8777 - val_accuracy: 0.0975 - val_loss: 3.7843\n",
      "Epoch 6/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0823 - loss: 3.7805 - val_accuracy: 0.1049 - val_loss: 3.6840\n",
      "Epoch 7/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0911 - loss: 3.6892 - val_accuracy: 0.1133 - val_loss: 3.5940\n",
      "Epoch 8/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0997 - loss: 3.6150 - val_accuracy: 0.1263 - val_loss: 3.5135\n",
      "Epoch 9/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1064 - loss: 3.5585 - val_accuracy: 0.1467 - val_loss: 3.4509\n",
      "Epoch 10/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1108 - loss: 3.4974 - val_accuracy: 0.1643 - val_loss: 3.3965\n",
      "Epoch 11/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1222 - loss: 3.4580 - val_accuracy: 0.1662 - val_loss: 3.3504\n",
      "Epoch 12/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1321 - loss: 3.4106 - val_accuracy: 0.1820 - val_loss: 3.3150\n",
      "Epoch 13/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1370 - loss: 3.3810 - val_accuracy: 0.1876 - val_loss: 3.2794\n",
      "Epoch 14/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1429 - loss: 3.3443 - val_accuracy: 0.1792 - val_loss: 3.2503\n",
      "Epoch 15/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1428 - loss: 3.3224 - val_accuracy: 0.2015 - val_loss: 3.2124\n",
      "Epoch 16/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1464 - loss: 3.2988 - val_accuracy: 0.1941 - val_loss: 3.1987\n",
      "Epoch 17/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1502 - loss: 3.2832 - val_accuracy: 0.2071 - val_loss: 3.1740\n",
      "Epoch 18/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1525 - loss: 3.2602 - val_accuracy: 0.2191 - val_loss: 3.1328\n",
      "Epoch 19/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1540 - loss: 3.2431 - val_accuracy: 0.2145 - val_loss: 3.1156\n",
      "Epoch 20/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1620 - loss: 3.2137 - val_accuracy: 0.2126 - val_loss: 3.1005\n",
      "Epoch 21/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1613 - loss: 3.1994 - val_accuracy: 0.2358 - val_loss: 3.0794\n",
      "Epoch 22/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1629 - loss: 3.1879 - val_accuracy: 0.2098 - val_loss: 3.0871\n",
      "Epoch 23/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 3.1738 - val_accuracy: 0.2331 - val_loss: 3.0492\n",
      "Epoch 24/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1747 - loss: 3.1587 - val_accuracy: 0.2256 - val_loss: 3.0465\n",
      "Epoch 25/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1760 - loss: 3.1558 - val_accuracy: 0.2303 - val_loss: 3.0234\n",
      "Epoch 26/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1780 - loss: 3.1232 - val_accuracy: 0.2228 - val_loss: 3.0124\n",
      "Epoch 27/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1822 - loss: 3.1211 - val_accuracy: 0.2256 - val_loss: 2.9905\n",
      "Epoch 28/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1815 - loss: 3.1093 - val_accuracy: 0.2358 - val_loss: 2.9943\n",
      "Epoch 29/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1860 - loss: 3.0913 - val_accuracy: 0.2386 - val_loss: 2.9859\n",
      "Epoch 30/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1907 - loss: 3.0894 - val_accuracy: 0.2303 - val_loss: 2.9762\n",
      "Epoch 31/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1874 - loss: 3.0809 - val_accuracy: 0.2340 - val_loss: 2.9580\n",
      "Epoch 32/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1916 - loss: 3.0690 - val_accuracy: 0.2386 - val_loss: 2.9535\n",
      "Epoch 33/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1978 - loss: 3.0525 - val_accuracy: 0.2405 - val_loss: 2.9408\n",
      "Epoch 34/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1911 - loss: 3.0581 - val_accuracy: 0.2405 - val_loss: 2.9338\n",
      "Epoch 35/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1985 - loss: 3.0402 - val_accuracy: 0.2442 - val_loss: 2.9248\n",
      "Epoch 36/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2030 - loss: 3.0292 - val_accuracy: 0.2396 - val_loss: 2.9018\n",
      "Epoch 37/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1994 - loss: 3.0242 - val_accuracy: 0.2396 - val_loss: 2.8915\n",
      "Epoch 38/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1993 - loss: 3.0231 - val_accuracy: 0.2340 - val_loss: 2.9112\n",
      "Epoch 39/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1983 - loss: 3.0111 - val_accuracy: 0.2451 - val_loss: 2.8771\n",
      "Epoch 40/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2041 - loss: 2.9911 - val_accuracy: 0.2535 - val_loss: 2.8791\n",
      "Epoch 41/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2040 - loss: 3.0003 - val_accuracy: 0.2544 - val_loss: 2.8576\n",
      "Epoch 42/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2135 - loss: 2.9767 - val_accuracy: 0.2488 - val_loss: 2.8777\n",
      "Epoch 43/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2113 - loss: 2.9747 - val_accuracy: 0.2553 - val_loss: 2.8528\n",
      "Epoch 44/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2112 - loss: 2.9559 - val_accuracy: 0.2721 - val_loss: 2.8347\n",
      "Epoch 45/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2190 - loss: 2.9567 - val_accuracy: 0.2646 - val_loss: 2.8279\n",
      "Epoch 46/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2164 - loss: 2.9422 - val_accuracy: 0.2656 - val_loss: 2.8190\n",
      "Epoch 47/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2135 - loss: 2.9426 - val_accuracy: 0.2572 - val_loss: 2.8217\n",
      "Epoch 48/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2192 - loss: 2.9424 - val_accuracy: 0.2702 - val_loss: 2.8076\n",
      "Epoch 49/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2160 - loss: 2.9302 - val_accuracy: 0.2665 - val_loss: 2.8129\n",
      "Epoch 50/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2251 - loss: 2.9199 - val_accuracy: 0.2693 - val_loss: 2.7887\n",
      "Epoch 51/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2274 - loss: 2.9138 - val_accuracy: 0.2758 - val_loss: 2.7928\n",
      "Epoch 52/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2318 - loss: 2.9096 - val_accuracy: 0.2730 - val_loss: 2.7762\n",
      "Epoch 53/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2298 - loss: 2.8972 - val_accuracy: 0.2693 - val_loss: 2.7759\n",
      "Epoch 54/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2353 - loss: 2.8934 - val_accuracy: 0.2878 - val_loss: 2.7468\n",
      "Epoch 55/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2296 - loss: 2.8885 - val_accuracy: 0.2878 - val_loss: 2.7600\n",
      "Epoch 56/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2298 - loss: 2.8691 - val_accuracy: 0.2721 - val_loss: 2.7488\n",
      "Epoch 57/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2325 - loss: 2.8759 - val_accuracy: 0.2925 - val_loss: 2.7346\n",
      "Epoch 58/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2354 - loss: 2.8634 - val_accuracy: 0.2916 - val_loss: 2.7387\n",
      "Epoch 59/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2414 - loss: 2.8490 - val_accuracy: 0.2721 - val_loss: 2.7411\n",
      "Epoch 60/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2450 - loss: 2.8346 - val_accuracy: 0.2860 - val_loss: 2.7205\n",
      "Epoch 61/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2373 - loss: 2.8412 - val_accuracy: 0.3008 - val_loss: 2.7115\n",
      "Epoch 62/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2481 - loss: 2.8301 - val_accuracy: 0.2916 - val_loss: 2.7026\n",
      "Epoch 63/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2446 - loss: 2.8199 - val_accuracy: 0.3027 - val_loss: 2.6899\n",
      "Epoch 64/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2470 - loss: 2.8291 - val_accuracy: 0.3045 - val_loss: 2.6809\n",
      "Epoch 65/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2437 - loss: 2.8189 - val_accuracy: 0.3027 - val_loss: 2.6848\n",
      "Epoch 66/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2467 - loss: 2.8067 - val_accuracy: 0.2981 - val_loss: 2.6781\n",
      "Epoch 67/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2511 - loss: 2.8043 - val_accuracy: 0.3055 - val_loss: 2.6670\n",
      "Epoch 68/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2587 - loss: 2.7969 - val_accuracy: 0.3129 - val_loss: 2.6481\n",
      "Epoch 69/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2588 - loss: 2.7835 - val_accuracy: 0.3120 - val_loss: 2.6483\n",
      "Epoch 70/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2557 - loss: 2.7847 - val_accuracy: 0.2934 - val_loss: 2.6727\n",
      "Epoch 71/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2610 - loss: 2.7724 - val_accuracy: 0.3120 - val_loss: 2.6460\n",
      "Epoch 72/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2605 - loss: 2.7678 - val_accuracy: 0.3138 - val_loss: 2.6456\n",
      "Epoch 73/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2611 - loss: 2.7597 - val_accuracy: 0.3008 - val_loss: 2.6365\n",
      "Epoch 74/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2606 - loss: 2.7553 - val_accuracy: 0.3148 - val_loss: 2.6216\n",
      "Epoch 75/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2563 - loss: 2.7571 - val_accuracy: 0.3018 - val_loss: 2.6389\n",
      "Epoch 76/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2654 - loss: 2.7474 - val_accuracy: 0.3129 - val_loss: 2.6125\n",
      "Epoch 77/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2657 - loss: 2.7298 - val_accuracy: 0.3138 - val_loss: 2.6147\n",
      "Epoch 78/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2719 - loss: 2.7295 - val_accuracy: 0.3250 - val_loss: 2.6047\n",
      "Epoch 79/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2661 - loss: 2.7320 - val_accuracy: 0.3231 - val_loss: 2.5929\n",
      "Epoch 80/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2680 - loss: 2.7179 - val_accuracy: 0.3129 - val_loss: 2.5929\n",
      "Epoch 81/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2711 - loss: 2.7182 - val_accuracy: 0.3203 - val_loss: 2.5889\n",
      "Epoch 82/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2750 - loss: 2.6989 - val_accuracy: 0.3361 - val_loss: 2.5664\n",
      "Epoch 83/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2803 - loss: 2.7056 - val_accuracy: 0.3268 - val_loss: 2.5738\n",
      "Epoch 84/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2805 - loss: 2.7024 - val_accuracy: 0.3305 - val_loss: 2.5708\n",
      "Epoch 85/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2791 - loss: 2.6983 - val_accuracy: 0.3296 - val_loss: 2.5608\n",
      "Epoch 86/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2797 - loss: 2.6916 - val_accuracy: 0.3166 - val_loss: 2.5681\n",
      "Epoch 87/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2784 - loss: 2.6850 - val_accuracy: 0.3315 - val_loss: 2.5383\n",
      "Epoch 88/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2774 - loss: 2.6921 - val_accuracy: 0.3324 - val_loss: 2.5484\n",
      "Epoch 89/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2860 - loss: 2.6779 - val_accuracy: 0.3389 - val_loss: 2.5308\n",
      "Epoch 90/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2854 - loss: 2.6697 - val_accuracy: 0.3352 - val_loss: 2.5167\n",
      "Epoch 91/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2850 - loss: 2.6711 - val_accuracy: 0.3370 - val_loss: 2.5219\n",
      "Epoch 92/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2859 - loss: 2.6501 - val_accuracy: 0.3296 - val_loss: 2.5273\n",
      "Epoch 93/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2912 - loss: 2.6500 - val_accuracy: 0.3352 - val_loss: 2.5139\n",
      "Epoch 94/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2878 - loss: 2.6433 - val_accuracy: 0.3343 - val_loss: 2.5177\n",
      "Epoch 95/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2903 - loss: 2.6414 - val_accuracy: 0.3528 - val_loss: 2.5069\n",
      "Epoch 96/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2881 - loss: 2.6439 - val_accuracy: 0.3491 - val_loss: 2.4954\n",
      "Epoch 97/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2888 - loss: 2.6467 - val_accuracy: 0.3361 - val_loss: 2.5112\n",
      "Epoch 98/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2881 - loss: 2.6346 - val_accuracy: 0.3630 - val_loss: 2.4829\n",
      "Epoch 99/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2959 - loss: 2.6345 - val_accuracy: 0.3268 - val_loss: 2.5007\n",
      "Epoch 100/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2950 - loss: 2.6175 - val_accuracy: 0.3408 - val_loss: 2.4871\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.68      0.52        19\n",
      "           1       0.56      0.45      0.50        11\n",
      "           2       0.59      0.89      0.71        19\n",
      "           3       0.50      0.38      0.43         8\n",
      "           4       0.25      0.20      0.22        15\n",
      "           5       0.71      0.38      0.50        13\n",
      "           6       0.19      0.16      0.17        19\n",
      "           7       0.41      0.47      0.44        19\n",
      "           8       0.17      0.26      0.20        19\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.14      0.11      0.12        19\n",
      "          11       0.00      0.00      0.00         8\n",
      "          12       0.31      0.58      0.41        19\n",
      "          13       0.43      0.38      0.40         8\n",
      "          14       0.20      0.26      0.23        19\n",
      "          15       0.00      0.00      0.00        19\n",
      "          16       0.40      0.74      0.52        19\n",
      "          17       0.35      0.37      0.36        19\n",
      "          18       0.70      0.74      0.72        19\n",
      "          19       0.70      0.84      0.76        19\n",
      "          20       0.33      0.63      0.44        19\n",
      "          21       0.14      0.11      0.12        19\n",
      "          22       0.50      0.25      0.33        12\n",
      "          23       0.69      0.58      0.63        19\n",
      "          24       0.52      0.68      0.59        19\n",
      "          25       0.14      0.05      0.08        19\n",
      "          26       0.43      0.63      0.51        19\n",
      "          27       0.71      0.62      0.67        16\n",
      "          28       0.57      0.42      0.48        19\n",
      "          29       0.50      0.63      0.56        19\n",
      "          30       0.29      0.17      0.21        12\n",
      "          31       0.55      0.84      0.67        19\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       0.30      0.21      0.25        14\n",
      "          34       0.67      0.67      0.67         9\n",
      "          35       0.33      0.43      0.38         7\n",
      "          36       0.50      0.74      0.60        19\n",
      "          37       0.45      0.26      0.33        19\n",
      "          38       0.36      0.47      0.41        19\n",
      "          39       0.26      0.44      0.33        18\n",
      "          40       0.24      0.26      0.25        19\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.30      0.16      0.21        19\n",
      "          43       0.08      0.05      0.06        19\n",
      "          44       0.31      0.53      0.39        19\n",
      "          45       0.27      0.16      0.20        19\n",
      "          46       0.28      0.26      0.27        19\n",
      "          47       0.30      0.32      0.31        19\n",
      "          48       0.50      0.21      0.30        19\n",
      "          49       0.14      0.11      0.12        19\n",
      "          50       0.16      0.32      0.21        19\n",
      "          51       0.29      0.43      0.34        14\n",
      "          52       0.14      0.05      0.08        19\n",
      "          53       0.32      0.47      0.38        19\n",
      "          54       0.00      0.00      0.00        19\n",
      "          55       0.00      0.00      0.00        10\n",
      "          56       0.12      0.16      0.14        19\n",
      "          57       0.00      0.00      0.00        18\n",
      "          58       0.20      0.21      0.21        19\n",
      "          59       0.00      0.00      0.00        19\n",
      "          60       0.17      0.11      0.13        19\n",
      "          61       0.20      0.28      0.23        18\n",
      "          62       0.43      0.63      0.51        19\n",
      "          63       0.20      0.16      0.18        19\n",
      "          64       0.14      0.05      0.08        19\n",
      "\n",
      "    accuracy                           0.35      1077\n",
      "   macro avg       0.31      0.33      0.31      1077\n",
      "weighted avg       0.32      0.35      0.32      1077\n",
      "\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3491 - loss: 2.4903 \n",
      "Test loss: 2.4903252124786377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# 1. Huấn luyện mô hình Word2Vec trên dữ liệu text của bạn\n",
    "sentences = [text.split() for text in df_train['text']]\n",
    "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# 2. Viết hàm để chuyển mỗi câu thành vector trung bình\n",
    "def sentence_to_avg_vector(text, model):\n",
    "# ... (Implement logic)\n",
    "    words = text.split()\n",
    "    vectors = []\n",
    "    vectors = [model.wv[word] if word in model.wv else np.zeros(100) for word in words]   \n",
    "    avg_vector = np.mean(vectors ,axis=0)\n",
    "    return avg_vector\n",
    "\n",
    "# 3. Tạo dữ liệu train/val/test X_train_avg, X_val_avg, X_test_avg\n",
    "X_train_avg = np.array([sentence_to_avg_vector(t, w2v_model) for t in df_train['text']])\n",
    "X_val_avg = np.array([sentence_to_avg_vector(t, w2v_model) for t in df_val['text']])\n",
    "X_test_avg = np.array([sentence_to_avg_vector(t, w2v_model) for t in df_test['text']])\n",
    "\n",
    "y_train = df_train[\"intent\"].values\n",
    "y_val   = df_val[\"intent\"].values\n",
    "y_test  = df_test[\"intent\"].values\n",
    "\n",
    "# 4. Xây dựng mô hình Sequential của Keras\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(w2v_model.vector_size,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# 5. Compile, huấn luyện và đánh giá mô hình\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_avg, y_train,\n",
    "    validation_data=(X_val_avg, y_val), \n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "y_pred_probs = model.predict(X_test_avg)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Test loss:\", model.evaluate(X_test_avg, y_test, verbose=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c06948c",
   "metadata": {},
   "source": [
    "### Nhiệm vụ 3: Mô hình Nâng cao (Embedding Pre-trained + LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "070733b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0163 - loss: 4.1508 - val_accuracy: 0.0186 - val_loss: 4.1410\n",
      "Epoch 2/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.0247 - loss: 4.0748 - val_accuracy: 0.0409 - val_loss: 3.9291\n",
      "Epoch 3/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.0424 - loss: 3.9368 - val_accuracy: 0.0511 - val_loss: 3.9190\n",
      "Epoch 4/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0518 - loss: 3.8937 - val_accuracy: 0.0539 - val_loss: 3.8002\n",
      "Epoch 5/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0494 - loss: 3.8615 - val_accuracy: 0.0622 - val_loss: 3.7571\n",
      "Epoch 6/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0554 - loss: 3.8319 - val_accuracy: 0.0594 - val_loss: 3.7388\n",
      "Epoch 7/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0612 - loss: 3.7730 - val_accuracy: 0.0761 - val_loss: 3.6779\n",
      "Epoch 8/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0634 - loss: 3.7271 - val_accuracy: 0.0706 - val_loss: 3.6356\n",
      "Epoch 9/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0699 - loss: 3.6840 - val_accuracy: 0.0613 - val_loss: 3.6473\n",
      "Epoch 10/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0682 - loss: 3.6465 - val_accuracy: 0.0938 - val_loss: 3.5655\n",
      "Epoch 11/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0783 - loss: 3.5997 - val_accuracy: 0.0956 - val_loss: 3.4959\n",
      "Epoch 12/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0792 - loss: 3.5754 - val_accuracy: 0.0882 - val_loss: 3.4657\n",
      "Epoch 13/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.0862 - loss: 3.5322 - val_accuracy: 0.1049 - val_loss: 3.4283\n",
      "Epoch 14/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0842 - loss: 3.5031 - val_accuracy: 0.1049 - val_loss: 3.4025\n",
      "Epoch 15/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0901 - loss: 3.5000 - val_accuracy: 0.1096 - val_loss: 3.3899\n",
      "Epoch 16/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.0905 - loss: 3.4875 - val_accuracy: 0.1133 - val_loss: 3.3945\n",
      "Epoch 17/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.0927 - loss: 3.4716 - val_accuracy: 0.0956 - val_loss: 3.3801\n",
      "Epoch 18/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0865 - loss: 3.5946 - val_accuracy: 0.0334 - val_loss: 4.5059\n",
      "Epoch 19/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0353 - loss: 3.9986 - val_accuracy: 0.0817 - val_loss: 3.7006\n",
      "Epoch 20/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.0630 - loss: 3.7284 - val_accuracy: 0.0799 - val_loss: 3.6397\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.57      0.63      0.60        19\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        13\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.00      0.00      0.00        19\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00        19\n",
      "          11       0.00      0.00      0.00         8\n",
      "          12       0.02      0.16      0.03        19\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.00      0.00      0.00        19\n",
      "          15       0.00      0.00      0.00        19\n",
      "          16       0.00      0.00      0.00        19\n",
      "          17       0.03      0.05      0.04        19\n",
      "          18       0.38      0.32      0.34        19\n",
      "          19       0.46      0.58      0.51        19\n",
      "          20       0.00      0.00      0.00        19\n",
      "          21       0.00      0.00      0.00        19\n",
      "          22       0.00      0.00      0.00        12\n",
      "          23       0.00      0.00      0.00        19\n",
      "          24       0.10      0.74      0.18        19\n",
      "          25       0.00      0.00      0.00        19\n",
      "          26       0.19      0.47      0.27        19\n",
      "          27       0.50      0.12      0.20        16\n",
      "          28       0.00      0.00      0.00        19\n",
      "          29       0.22      0.68      0.33        19\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.37      0.84      0.52        19\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       0.00      0.00      0.00        14\n",
      "          34       0.00      0.00      0.00         9\n",
      "          35       0.00      0.00      0.00         7\n",
      "          36       0.07      0.42      0.12        19\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.00      0.00      0.00        19\n",
      "          39       0.00      0.00      0.00        18\n",
      "          40       0.00      0.00      0.00        19\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.00      0.00      0.00        19\n",
      "          43       0.00      0.00      0.00        19\n",
      "          44       0.00      0.00      0.00        19\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.00      0.00      0.00        19\n",
      "          47       0.00      0.00      0.00        19\n",
      "          48       0.02      0.05      0.02        19\n",
      "          49       0.08      0.21      0.12        19\n",
      "          50       0.04      0.42      0.07        19\n",
      "          51       0.00      0.00      0.00        14\n",
      "          52       0.00      0.00      0.00        19\n",
      "          53       0.00      0.00      0.00        19\n",
      "          54       0.14      0.11      0.12        19\n",
      "          55       0.00      0.00      0.00        10\n",
      "          56       0.00      0.00      0.00        19\n",
      "          57       0.00      0.00      0.00        18\n",
      "          58       0.00      0.00      0.00        19\n",
      "          59       0.00      0.00      0.00        19\n",
      "          60       0.00      0.00      0.00        19\n",
      "          61       0.00      0.00      0.00        18\n",
      "          62       0.20      0.47      0.28        19\n",
      "          63       0.00      0.00      0.00        19\n",
      "          64       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.11      1077\n",
      "   macro avg       0.05      0.10      0.06      1077\n",
      "weighted avg       0.06      0.11      0.07      1077\n",
      "\n",
      "\u001b[1m17/34\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1038 - loss: 3.3893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1105 - loss: 3.4021\n",
      "Test loss: 3.4021434783935547\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 1. Tiền xử lý cho mô hình chuỗi\n",
    "# a. Tokenizer: Tạo vocab và chuyển text thành chuỗi chỉ số\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(df_train[\"text\"])\n",
    "\n",
    "# Chuyển text sang sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(df_train[\"text\"])\n",
    "val_sequences   = tokenizer.texts_to_sequences(df_val[\"text\"])\n",
    "test_sequences  = tokenizer.texts_to_sequences(df_test[\"text\"])\n",
    "\n",
    "# b. Padding: Đảm bảo các chuỗi có cùng độ dài\n",
    "max_len = 50\n",
    "X_train_pad = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
    "X_val_pad   = pad_sequences(val_sequences, maxlen=max_len, padding='post')\n",
    "X_test_pad  = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# 2. Tạo ma trận trọng số cho Embedding Layer từ Word2Vec\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = w2v_model.vector_size\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "# 3. Xây dựng mô hình Sequential với LSTM\n",
    "lstm_model_pretrained = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix], # Khởi tạo trọng số\n",
    "        input_length=max_len,\n",
    "        trainable=False # Đóng băng lớp Embedding\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "# 4. Compile, huấn luyện (sử dụng EarlyStopping) và đánh giá\n",
    "lstm_model_pretrained.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # Nhãn dạng số nguyên\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = lstm_model_pretrained.fit(\n",
    "    X_train_pad, df_train[\"intent\"].values,\n",
    "    validation_data=(X_val_pad, df_val[\"intent\"].values),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "y_pred_probs = lstm_model_pretrained.predict(X_test_pad)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Test loss:\", lstm_model_pretrained.evaluate(X_test_pad, y_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc62ae",
   "metadata": {},
   "source": [
    "### Nhiệm vụ 4: Mô hình Nâng cao (Embedding học từ đầu + LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa25052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0168 - loss: 4.1506 - val_accuracy: 0.0176 - val_loss: 4.1339\n",
      "Epoch 2/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.0163 - loss: 4.1385 - val_accuracy: 0.0176 - val_loss: 4.1312\n",
      "Epoch 3/50\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.0143 - loss: 4.1368 - val_accuracy: 0.0176 - val_loss: 4.1331\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        19\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        13\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.00      0.00      0.00        19\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00        19\n",
      "          11       0.00      0.00      0.00         8\n",
      "          12       0.00      0.00      0.00        19\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.00      0.00      0.00        19\n",
      "          15       0.00      0.00      0.00        19\n",
      "          16       0.00      0.00      0.00        19\n",
      "          17       0.00      0.00      0.00        19\n",
      "          18       0.00      0.00      0.00        19\n",
      "          19       0.02      1.00      0.03        19\n",
      "          20       0.00      0.00      0.00        19\n",
      "          21       0.00      0.00      0.00        19\n",
      "          22       0.00      0.00      0.00        12\n",
      "          23       0.00      0.00      0.00        19\n",
      "          24       0.00      0.00      0.00        19\n",
      "          25       0.00      0.00      0.00        19\n",
      "          26       0.00      0.00      0.00        19\n",
      "          27       0.00      0.00      0.00        16\n",
      "          28       0.00      0.00      0.00        19\n",
      "          29       0.00      0.00      0.00        19\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        19\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       0.00      0.00      0.00        14\n",
      "          34       0.00      0.00      0.00         9\n",
      "          35       0.00      0.00      0.00         7\n",
      "          36       0.00      0.00      0.00        19\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.00      0.00      0.00        19\n",
      "          39       0.00      0.00      0.00        18\n",
      "          40       0.00      0.00      0.00        19\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.00      0.00      0.00        19\n",
      "          43       0.00      0.00      0.00        19\n",
      "          44       0.00      0.00      0.00        19\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.00      0.00      0.00        19\n",
      "          47       0.00      0.00      0.00        19\n",
      "          48       0.00      0.00      0.00        19\n",
      "          49       0.00      0.00      0.00        19\n",
      "          50       0.00      0.00      0.00        19\n",
      "          51       0.00      0.00      0.00        14\n",
      "          52       0.00      0.00      0.00        19\n",
      "          53       0.00      0.00      0.00        19\n",
      "          54       0.00      0.00      0.00        19\n",
      "          55       0.00      0.00      0.00        10\n",
      "          56       0.00      0.00      0.00        19\n",
      "          57       0.00      0.00      0.00        18\n",
      "          58       0.00      0.00      0.00        19\n",
      "          59       0.00      0.00      0.00        19\n",
      "          60       0.00      0.00      0.00        19\n",
      "          61       0.00      0.00      0.00        18\n",
      "          62       0.00      0.00      0.00        19\n",
      "          63       0.00      0.00      0.00        19\n",
      "          64       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.02      1077\n",
      "   macro avg       0.00      0.02      0.00      1077\n",
      "weighted avg       0.00      0.02      0.00      1077\n",
      "\n",
      "\u001b[1m21/34\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0231 - loss: 4.1776  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NGUYEN PHUONG BICH\\HOC_TAP\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0176 - loss: 4.1339\n",
      "Test loss: [4.133893966674805, 0.017641596496105194]\n"
     ]
    }
   ],
   "source": [
    "# Dữ liệu đã được tiền xử lý (tokenized, padded) từ nhiệm vụ 3\n",
    "# 1. Xây dựng mô hình\n",
    "lstm_model_scratch = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=100, # Chọn một chiều embedding, ví dụ 100\n",
    "        input_length=max_len\n",
    "        # Không có weights, trainable=True (mặc định)\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "# 2. Compile, huấn luyện và đánh giá mô hình\n",
    "lstm_model_scratch.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = lstm_model_scratch.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "y_pred_probs = lstm_model_scratch.predict(X_test_pad)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Test loss:\", lstm_model_scratch.evaluate(X_test_pad, y_test, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eebaea",
   "metadata": {},
   "source": [
    "### Nhiệm vụ 5: Đánh giá, So sánh và Phân tích"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17d4576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Sentence: can you remind me to not call my mom\n",
      "TF-IDF + LR: play_podcasts\n",
      "Word2Vec Avg + Dense: datetime_query\n",
      "LSTM Pretrained: iot_hue_lightoff\n",
      "LSTM Scratch: transport_taxi\n",
      "######################################################################\n",
      "Sentence: is it going to be sunny or rainy tomorrow\n",
      "TF-IDF + LR: iot_wemo_on\n",
      "Word2Vec Avg + Dense: alarm_remove\n",
      "LSTM Pretrained: iot_hue_lightchange\n",
      "LSTM Scratch: transport_taxi\n",
      "######################################################################\n",
      "Sentence: find a flight from new york to london but not through paris\n",
      "TF-IDF + LR: cooking_recipe\n",
      "Word2Vec Avg + Dense: general_praise\n",
      "LSTM Pretrained: general_repeat\n",
      "LSTM Scratch: transport_taxi\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "# Câu kiểm tra\n",
    "test_sentences = [\n",
    "    \"can you remind me to not call my mom\",\n",
    "    \"is it going to be sunny or rainy tomorrow\",\n",
    "    \"find a flight from new york to london but not through paris\"\n",
    "]\n",
    "\n",
    "# 1. TF-IDF + Logistic Regression\n",
    "pred_tfidf = tfidf_lr_pipeline.predict(test_sentences)\n",
    "\n",
    "# 2. Word2Vec Avg + Dense\n",
    "def sentence_to_avg_vector(text, model):\n",
    "    words = text.split()\n",
    "    vectors = [model.wv[word] if word in model.wv else np.zeros(model.vector_size) for word in words]\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "X_w2v = np.array([sentence_to_avg_vector(s, w2v_model) for s in test_sentences])\n",
    "pred_w2v = np.argmax(model.predict(X_w2v), axis=1)\n",
    "\n",
    "# 3. LSTM pretrained embedding\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "X_pad = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "pred_lstm_pretrained = np.argmax(lstm_model_pretrained.predict(X_pad), axis=1)\n",
    "\n",
    "# 4. LSTM scratch\n",
    "pred_lstm_scratch = np.argmax(lstm_model_scratch.predict(X_pad), axis=1)\n",
    "\n",
    "# In kết quả\n",
    "for i, sent in enumerate(test_sentences):\n",
    "    print(f\"Sentence: {sent}\")\n",
    "    print(f\"TF-IDF + LR: {classes[pred_tfidf[i]]}\")\n",
    "    print(f\"Word2Vec Avg + Dense: {classes[pred_w2v[i]]}\")\n",
    "    print(f\"LSTM Pretrained: {classes[pred_lstm_pretrained[i]]}\")\n",
    "    print(f\"LSTM Scratch: {classes[pred_lstm_scratch[i]]}\")\n",
    "    print(\"#\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
