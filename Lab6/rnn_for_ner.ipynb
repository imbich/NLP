{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niU3frsYMZOB"
      },
      "source": [
        "# Xây dựng mô hình RNN cho bài toán Nhận dạng thực thể tên (NER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qllVOhwIMfXG"
      },
      "source": [
        "## Task 1: Tải và tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6FU-4EjHdhJ",
        "outputId": "05df1e8d-0b4d-4a0a-9ca7-d149875aa2bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
            "        num_rows: 14041\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
            "        num_rows: 3250\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
            "        num_rows: 3453\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"conll2003\")\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjc84ba3NBHl",
        "outputId": "aa856982-547e-4b57-9302-0f15369854b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Danh sách nhãn: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
            "Sentence: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
            "NER IDs: [3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
            "NER Labels: ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "# Trích xuất câu và nhãn dạng số\n",
        "train_sentences = dataset[\"train\"][\"tokens\"]\n",
        "train_tags = dataset[\"train\"][\"ner_tags\"]\n",
        "\n",
        "val_sentences = dataset[\"validation\"][\"tokens\"]\n",
        "val_tags = dataset[\"validation\"][\"ner_tags\"]\n",
        "\n",
        "test_sentences = dataset[\"test\"][\"tokens\"]\n",
        "test_tags = dataset[\"test\"][\"ner_tags\"]\n",
        "\n",
        "# Lấy ánh xạ số -> tên nhãn\n",
        "label_names = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
        "print(\"Danh sách nhãn:\", label_names)\n",
        "\n",
        "# Hàm chuyển từng nhãn số sang nhãn text\n",
        "def convert_tags(tag_ids):\n",
        "    return [label_names[i] for i in tag_ids]\n",
        "\n",
        "# Chuyển đổi toàn bộ train/val/test\n",
        "train_tags_str = [convert_tags(seq) for seq in train_tags]\n",
        "val_tags_str = [convert_tags(seq) for seq in val_tags]\n",
        "test_tags_str = [convert_tags(seq) for seq in test_tags]\n",
        "\n",
        "# In thử một câu và nhãn\n",
        "print(\"Sentence:\", train_sentences[0])\n",
        "print(\"NER IDs:\", train_tags[0])\n",
        "print(\"NER Labels:\", train_tags_str[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA2Wb0R6Nno_",
        "outputId": "e18a267c-5d07-4218-bad6-cbe80c2033f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Số lượng từ trong word_to_ix: 23625\n",
            "Số lượng nhãn trong tag_to_ix: 9\n",
            "Ví dụ trong word_to_ix: [('<PAD>', 0), ('<UNK>', 1), ('EU', 2), ('rejects', 3), ('German', 4), ('call', 5), ('to', 6), ('boycott', 7), ('British', 8), ('lamb', 9)]\n",
            "tag_to_ix: {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n"
          ]
        }
      ],
      "source": [
        "word_to_ix = {\n",
        "    \"<PAD>\": 0,\n",
        "    \"<UNK>\": 1\n",
        "}\n",
        "\n",
        "# Duyệt toàn bộ câu để thêm từ vào từ điển\n",
        "for sentence in train_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "tag_to_ix = {}\n",
        "for tag in label_names:\n",
        "    if tag not in tag_to_ix:\n",
        "        tag_to_ix[tag] = len(tag_to_ix)\n",
        "\n",
        "print(\"Số lượng từ trong word_to_ix:\", len(word_to_ix))\n",
        "print(\"Số lượng nhãn trong tag_to_ix:\", len(tag_to_ix))\n",
        "\n",
        "# In thử vài phần tử\n",
        "print(\"Ví dụ trong word_to_ix:\", list(word_to_ix.items())[:10])\n",
        "print(\"tag_to_ix:\", tag_to_ix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZpYao-1OUyf"
      },
      "source": [
        "## Task 2: Tạo PyTorch Dataset và DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ixzAAPZaOcpO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, tags, word_to_ix, tag_to_ix):\n",
        "        \"\"\"\n",
        "        sentences: list[list[token]]\n",
        "        tags: list[list[label_str]]\n",
        "        \"\"\"\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "\n",
        "        # id đặc biệt\n",
        "        self.unk_id = word_to_ix[\"<UNK>\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        tokens = self.sentences[index]\n",
        "        tag_seq = self.tags[index]\n",
        "\n",
        "        # Chuyển từ sang chỉ số\n",
        "        sent_idx = [\n",
        "            self.word_to_ix.get(tok, self.unk_id)\n",
        "            for tok in tokens\n",
        "        ]\n",
        "\n",
        "        # Chuyển nhãn sang chỉ số\n",
        "        tag_idx = [\n",
        "            self.tag_to_ix[tag] for tag in tag_seq\n",
        "        ]\n",
        "\n",
        "        return (\n",
        "            torch.tensor(sent_idx, dtype=torch.long),\n",
        "            torch.tensor(tag_idx, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "YR9wE5hRPD_h"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: list of (sent_tensor, tag_tensor)\n",
        "    \"\"\"\n",
        "    sentences, tags = zip(*batch)\n",
        "\n",
        "    # Padding cho câu\n",
        "    pad_id = word_to_ix[\"<PAD>\"]  # index của <PAD>\n",
        "    sentences_padded = pad_sequence(sentences, batch_first=True, padding_value=pad_id)\n",
        "\n",
        "    # Padding cho nhãn\n",
        "    tags_padded = pad_sequence(tags, batch_first=True, padding_value=-1)\n",
        "\n",
        "    return sentences_padded, tags_padded\n",
        "\n",
        "train_dataset = NERDataset(\n",
        "    train_sentences, train_tags_str, word_to_ix, tag_to_ix\n",
        ")\n",
        "\n",
        "val_dataset = NERDataset(\n",
        "    val_sentences, val_tags_str, word_to_ix, tag_to_ix\n",
        ")\n",
        "\n",
        "test_dataset = NERDataset(\n",
        "    test_sentences, test_tags_str, word_to_ix, tag_to_ix\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hkmH1d0Qce-"
      },
      "source": [
        "## Task 3: Xây dựng Mô hình RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "YXKlsuDHP7Ou"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMForNER(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, padding_idx=0, bidirectional=True):\n",
        "        \"\"\"\n",
        "        vocab_size: số từ trong từ điển\n",
        "        embedding_dim: kích thước embedding\n",
        "        hidden_dim: số neuron ẩn của LSTM\n",
        "        num_classes: số lượng nhãn NER\n",
        "        padding_idx: chỉ số dùng để pad\n",
        "        bidirectional: True nếu dùng BiLSTM\n",
        "        \"\"\"\n",
        "        super(LSTMForNER, self).__init__()\n",
        "\n",
        "        # 1. Embedding layer\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_dim,\n",
        "            padding_idx=padding_idx\n",
        "        )\n",
        "\n",
        "        # 2. LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        # 3. Linear layer: từ hidden_dim*2 nếu BiLSTM → num_classes\n",
        "        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)\n",
        "\n",
        "    def forward(self, x, lengths=None):\n",
        "        \"\"\"\n",
        "        x: (batch_size, seq_len) chứa index từ\n",
        "        lengths: độ dài thực của từng câu (dùng cho packed sequence)\n",
        "        \"\"\"\n",
        "        # Embedding\n",
        "        embedded = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        if lengths is not None:\n",
        "            packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
        "                embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "            )\n",
        "            packed_output, _ = self.lstm(packed_embedded)\n",
        "            output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "        else:\n",
        "            output, _ = self.lstm(embedded)  # (batch_size, seq_len, hidden_dim*2 nếu bidirectional)\n",
        "\n",
        "        logits = self.fc(output)  # (batch_size, seq_len, num_classes)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeaASecQfs2"
      },
      "source": [
        "## Task 4: Huấn luyện Mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "--_qNAU4QiYW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Thiết bị\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Giả sử bạn đã có:\n",
        "# model, train_loader, val_loader, tag_to_ix\n",
        "padding_tag_id = -1  # giống giá trị padding nhãn trong collate_fn\n",
        "\n",
        "# Khởi tạo mô hình\n",
        "vocab_size = len(word_to_ix)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "output_size = len(tag_to_ix)\n",
        "padding_idx = word_to_ix[\"<PAD>\"]\n",
        "\n",
        "model = LSTMForNER(vocab_size, embedding_dim, hidden_dim, output_size, padding_idx=padding_idx)\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=padding_tag_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWODy5gDQ49W",
        "outputId": "81b03da8-d592-4514-ac6d-a3a71b7d3833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 - Loss trung bình: 0.5765\n",
            "Epoch 2/5 - Loss trung bình: 0.2659\n",
            "Epoch 3/5 - Loss trung bình: 0.1529\n",
            "Epoch 4/5 - Loss trung bình: 0.0886\n",
            "Epoch 5/5 - Loss trung bình: 0.0489\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5  # hoặc 5 tùy nhu cầu\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch_sent, batch_tag in train_loader:\n",
        "        batch_sent = batch_sent.to(device)  # (batch_size, seq_len)\n",
        "        batch_tag = batch_tag.to(device)    # (batch_size, seq_len)\n",
        "\n",
        "        # 1. Xóa gradient cũ\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. Forward pass\n",
        "        logits = model(batch_sent)  # (batch_size, seq_len, num_classes)\n",
        "\n",
        "        # 3. Tính loss\n",
        "        # reshape logits và labels để CrossEntropyLoss nhận dạng\n",
        "        # từ (batch, seq_len, num_classes) → (batch*seq_len, num_classes)\n",
        "        logits_flat = logits.view(-1, output_size)\n",
        "        tags_flat = batch_tag.view(-1)\n",
        "\n",
        "        loss = criterion(logits_flat, tags_flat)\n",
        "\n",
        "        # 4. Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Cập nhật trọng số\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\"Epoch {epoch}/{num_epochs} - Loss trung bình: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "nenpH3_5RfZ2"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "def evaluate(model, data_loader, tag_to_ix, device):\n",
        "    model.eval()\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}  # ánh xạ chỉ số → tên nhãn\n",
        "\n",
        "    total_tokens = 0\n",
        "    correct_tokens = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_sent, batch_tag in data_loader:\n",
        "            batch_sent = batch_sent.to(device)\n",
        "            batch_tag = batch_tag.to(device)\n",
        "\n",
        "            logits = model(batch_sent)  # (batch, seq_len, num_classes)\n",
        "            preds = torch.argmax(logits, dim=-1)  # (batch, seq_len)\n",
        "\n",
        "            # Tính accuracy bỏ qua padding\n",
        "            mask = batch_tag != -1\n",
        "            total_tokens += mask.sum().item()\n",
        "            correct_tokens += ((preds == batch_tag) & mask).sum().item()\n",
        "\n",
        "            # Chuẩn bị dữ liệu cho seqeval\n",
        "            preds_list = []\n",
        "            labels_list = []\n",
        "\n",
        "            for p, t, m in zip(preds.cpu(), batch_tag.cpu(), mask.cpu()):\n",
        "                p_seq = [ix_to_tag[ix.item()] for ix, mask_val in zip(p, m) if mask_val]\n",
        "                t_seq = [ix_to_tag[ix.item()] for ix, mask_val in zip(t, m) if mask_val]\n",
        "                preds_list.append(p_seq)\n",
        "                labels_list.append(t_seq)\n",
        "\n",
        "            all_preds.extend(preds_list)\n",
        "            all_labels.extend(labels_list)\n",
        "\n",
        "    accuracy = correct_tokens / total_tokens\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Accuracy (token-level): {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "    print(\"\\nBáo cáo chi tiết theo thực thể:\")\n",
        "    print(classification_report(all_labels, all_preds))\n",
        "\n",
        "    return accuracy, precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt6T606ER84O",
        "outputId": "eebb8061-6332-4890-f33f-8905f9d21da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================== Trên tập Test ==============================\n",
            "Accuracy (token-level): 0.9188\n",
            "Precision: 0.7216, Recall: 0.5351, F1-score: 0.6145\n",
            "\n",
            "Báo cáo chi tiết theo thực thể:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.85      0.67      0.75      1668\n",
            "        MISC       0.61      0.58      0.60       702\n",
            "         ORG       0.69      0.51      0.59      1661\n",
            "         PER       0.66      0.40      0.50      1617\n",
            "\n",
            "   micro avg       0.72      0.54      0.61      5648\n",
            "   macro avg       0.70      0.54      0.61      5648\n",
            "weighted avg       0.72      0.54      0.61      5648\n",
            "\n",
            "============================== Trên tập Val ==============================\n",
            "Accuracy (token-level): 0.9438\n",
            "Precision: 0.8213, Recall: 0.6653, F1-score: 0.7351\n",
            "\n",
            "Báo cáo chi tiết theo thực thể:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.90      0.76      0.83      1837\n",
            "        MISC       0.79      0.71      0.75       922\n",
            "         ORG       0.77      0.64      0.70      1341\n",
            "         PER       0.78      0.57      0.66      1842\n",
            "\n",
            "   micro avg       0.82      0.67      0.74      5942\n",
            "   macro avg       0.81      0.67      0.73      5942\n",
            "weighted avg       0.82      0.67      0.73      5942\n",
            "\n",
            "Độ chính xác trên tập validation: 0.9438\n"
          ]
        }
      ],
      "source": [
        "print(f\"=\"*30, \"Trên tập Test\", \"=\"*30)\n",
        "accuracy, precision, recall, f1 = evaluate(model, test_loader, tag_to_ix, device)\n",
        "print(f\"=\"*30, \"Trên tập Val\", \"=\"*30)\n",
        "accuracy, precision, recall, f1 = evaluate(model, val_loader, tag_to_ix, device)\n",
        "\n",
        "print(f\"Độ chính xác trên tập validation: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "CLFscoZCTnjF"
      },
      "outputs": [],
      "source": [
        "def predict_sentence(sentence, model, word_to_ix, ix_to_tag, device):\n",
        "    \"\"\"\n",
        "    sentence: str, câu mới\n",
        "    model: mô hình NER đã huấn luyện\n",
        "    word_to_ix: từ điển từ -> index\n",
        "    ix_to_tag: từ điển index -> nhãn string\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tách câu thành danh sách token (simple split, có thể dùng tokenizer nâng cao)\n",
        "    tokens = sentence.split()\n",
        "\n",
        "    # Chuyển token -> index\n",
        "    indices = [word_to_ix.get(tok, word_to_ix[\"<UNK>\"]) for tok in tokens]\n",
        "\n",
        "    # Tạo tensor và đưa lên device\n",
        "    input_tensor = torch.tensor([indices], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)  # (1, seq_len, num_classes)\n",
        "        pred_indices = torch.argmax(logits, dim=-1).squeeze(0)  # (seq_len,)\n",
        "\n",
        "    # Chuyển chỉ số sang nhãn\n",
        "    pred_tags = [ix_to_tag[ix.item()] for ix in pred_indices]\n",
        "\n",
        "    # In ra cặp (từ, nhãn)\n",
        "    for tok, tag in zip(tokens, pred_tags):\n",
        "        print(f\"{tok}\\t{tag}\")\n",
        "\n",
        "    return list(zip(tokens, pred_tags))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DgfZcT6TvFl",
        "outputId": "b51685cc-5f83-4ffa-8edb-5aee3eccbd86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VNU\tB-ORG\n",
            "University\tI-ORG\n",
            "is\tO\n",
            "located\tO\n",
            "in\tO\n",
            "Hanoi\tB-LOC\n"
          ]
        }
      ],
      "source": [
        "# Chuẩn bị ánh xạ ngược\n",
        "ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "\n",
        "# Ví dụ dự đoán\n",
        "sentence = \"VNU University is located in Hanoi\"\n",
        "pred_pairs = predict_sentence(sentence, model, word_to_ix, ix_to_tag, device)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
